---
title: 并发理论接触：内存屏障
cover: false
toc: true
mathjax: false
date: 2022-04-21 15:29:30
tags:
  - 并发
  - Java
categories: 并发编程
url: 165052618
sort: 6
keywords:
password:
summary:
---
为了提高 CPU 的运行效率，现代计算机做了两个方面的优化。一是引入的缓存，二是增加了 CPU 乱序执行指令集。

引入缓存后，就出现了缓存一致性问题。为了解决缓存一致性问题，引入了 MESI 缓存一致性协议。同时为了优化 M -> I 状态的 CPU 等待时间，加入了 StoreBuffer 和 InvalidQueue，从而使 MESI 变成了弱一致性协议，只能实现最终一致。

CPU 乱序执行指令集在单线程情况下按照 as-if-serial 原则不会出现问题，但是在多线程下，对于一些共享变量就会出现一些问题，从而造成了指令重排现象。

这两种情况在并发情况下都会造成对共享变量的读写不一致问题，也就是指令重排的现象。但是从整体看，两种优化方案都是积极有利的，对并发情况下对于共享变量的操作，硬件系统提供了一种`内存屏障`的机制来禁止 MESI 的优化以及 CPU 乱序执行。

内存屏障

### 处理器乱序规则

上面我们说了处理器会发生指令重排,现在来简单的看看常见处理器允许的重排规则,换言之就是处理器可以对那些指令进行顺序调整:

| 处理器  | Load-Load | Load-Store | Store-Store | Store-Load | 数据依赖 |
| ------- | --------- | ---------- | ----------- | ---------- | -------- |
| x86     | N         | N          | N           | Y          | N        |
| PowerPC | Y         | Y          | Y           | Y          | N        |
| ia64    | Y         | Y          | Y           | Y          | N        |

表格中的Y表示前后两个操作允许重排,N则表示不允许重排.与这些规则对应是的禁止重排的内存屏障.

注意:处理器和编译都会遵循数据依赖性,不会改变存在数据依赖关系的两个操作的顺序.所谓的数据依赖性就是如果两个操作访问同一个变量,且这两个操作中有一个是写操作,那么久可以称这两个操作存在数据依赖性.举个简单例子:

```java
a=100;//write
b=a;//read

或者
a=100;//write
a=2000;//write
或者
a=b;//read
b=12;//write
```

以上所示的,两个操作之间不能发生重排,这是处理器和编译所必须遵循的.当然这里指的是发生在单个处理器或单个线程中.

### 内存屏障的分类

在开始看一下表格之前,务必确保自己了解Store和Load指令的含义.简单来说,Store就是将处理器缓存中的数据刷新到内存中,而Load则是从内存拷贝数据到缓存当中.

| 屏障类型            | 指令示例                 | 说明                                                         |
| ------------------- | ------------------------ | ------------------------------------------------------------ |
| LoadLoad Barriers   | Load1;LoadLoad;Load2     | 该屏障确保Load1数据的装载先于Load2及其后所有装载指令的的操作 |
| StoreStore Barriers | Store1;StoreStore;Store2 | 该屏障确保Store1立刻刷新数据到内存(使其对其他处理器可见)的操作先于Store2及其后所有存储指令的操作 |
| LoadStore Barriers  | Load1;LoadStore;Store2   | 确保Load1的数据装载先于Store2及其后所有的存储指令刷新数据到内存的操作 |
| StoreLoad Barriers  | Store1;StoreLoad;Load1   | 该屏障确保Store1立刻刷新数据到内存的操作先于Load2及其后所有装载装载指令的操作.它会使该屏障之前的所有内存访问指令(存储指令和访问指令)完成之后,才执行该屏障之后的内存访问指令 |

StoreLoad Barriers同时具备其他三个屏障的效果,因此也称之为全能屏障,是目前大多数处理器所支持的,但是相对其他屏障,该屏障的开销相对昂贵.在x86架构的处理器的指令集中,`lock`指令可以触发StoreLoad Barriers.

### 硬件层内存屏障

硬件层提供了一系列的内存屏障 memory barrier / memory fence(Intel的提法)来提供一致性的能

力。拿X86平台来说，有几种主要的内存屏障:

1. lfence，是一种Load Barrier 读屏障
2. sfence, 是一种Store Barrier 写屏障
3. mfence, 是一种全能型的屏障，具备lfence和sfence的能力
4. Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。它后面可以跟ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG, CMPXCH8B, DEC, INC, NEG, NOT, OR, SBB, SUB, XOR, XADD, and XCHG等指令。

#### lock前缀指令的作用

1. 确保后续指令执行的原子性。在Pentium及之前的处理器中，带有lock前缀的指令在执行期间会锁住 总线，使得其它处理器暂时无法通过总线访问内存，很显然，这个开销很大。在新的处理器中，Intel 使用缓存锁定来保证指令执行的原子性，缓存锁定将大大降低lock前缀指令的执行开销。
2. LOCK前缀指令具有类似于内存屏障的功能，禁止该指令与前面和后面的读写指令重排序。
3. LOCK前缀指令会等待它之前所有的指令完成、并且所有缓冲的写操作写回内存(也就是将store buffer中的内容写入内存)之后才开始执行，并且根据缓存一致性协议，刷新store buffer的操作会导致 其他cache中的副本失效。

#### 从硬件层面分析Lock前缀指令

[《64-ia-32-architectures-software-developer-vol-3a-part-1-manual.pdf》](https://gitee.com/yuanjianchen/programming-resources/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.pdf)中有如下描述:

>The 32-bit IA-32 processors support locked atomic operations on locations in system memory. These operations are typically used to manage shared data structures (such as semaphores, segment descriptors, system segments, or page tables) in which two or more processors may try simultaneously to modify the same field or flag. The processor uses three interdependent mechanisms for carrying out locked atomic operations:
>
>• Guaranteed atomic operations
>• Bus locking, using the LOCK# signal and the LOCK instruction prefix
>• Cache coherency protocols that ensure that atomic operations can be carried out on cached data structures (cache lock); this mechanism is present in the Pentium 4, Intel Xeon, and P6 family processors

32位的IA-32处理器支持对系统内存中的位置进行锁定的原子操作。这些操作通常用于管理共享的数据 结构(如信号量、段描述符、系统段或页表)，在这些结构中，两个或多个处理器可能同时试图修改相同的字 段或标志。处理器使用三种相互依赖的机制来执行锁定的原子操作:

* 有保证的原子操作
* 总线锁定，使用LOCK#信号和LOCK指令前缀
* 缓存一致性协议，确保原子操作可以在缓存的数据结构上执行(缓存锁);这种机制出现在Pentium 4，Intel Xeon和P6系列处理器中

#### 内存屏障有两个能力

1. 阻止屏障两边的指令重排序
2. 刷新处理器缓存/冲刷处理器缓存



对Load Barrier来说，在读指令前插入读屏障，可以让高速缓存中的数据失效，重新从主内存加载数据;对Store Barrier来说，在写指令之后插入写屏障，能让写入缓存的最新数据写回到主内存。 Lock前缀实现了类似的能力，它先对总线和缓存加锁，然后执行后面的指令，最后释放锁后会把高速缓存中的数据刷新回主内存。在Lock锁住总线的时候，其他CPU的读写请求都会被阻塞，直到锁释放。

>个人对于内存屏障的理解主要是内存屏障通过限制了 CPU 在操作变量时对内存读写的顺序而反映到 CPU 对于指令的执行顺序，可以结合{% post_link 'Java/并发编程/并发理论基础：缓存可见性、MESI' %}内存一致性协议的优化来整体理解。

参考：

[Memory Barriers: a Hardware View for Software Hackers](https://gitee.com/yuanjianchen/programming-resources/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA/hwViewForSwHackers.pdf)

[64-ia-32-architectures-software-developer-vol-3a-part-1-manual.pdf](https://gitee.com/yuanjianchen/programming-resources/blob/master/%E8%AE%A1%E7%AE%97%E6%9C%BA/64-ia-32-architectures-software-developer-vol-3a-part-1-manual.pdf)

